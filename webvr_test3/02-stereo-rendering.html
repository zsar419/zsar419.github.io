<!doctype html>
<!--
Copyright 2016 The Chromium Authors. All rights reserved.
Use of this source code is governed by a BSD-style license that can be
found in the LICENSE file.
-->
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes"> <!-- Fullscreen Landscape on iOS -->

    <title>02 - Stereo Rendering</title>

    <!--
      This sample demonstrates how to properly render stereo views of a scene
      using the VRDisplay's eye paramaters. Nothing is presented to the
      VRDisplay.
    -->

    <style>
      #webgl-canvas {
        position: absolute;
        width: 100%;
        height: 100%;
        left: 0;
        top: 0;
        margin: 0;
      }
    </style>

    <!-- This entire block in only to facilitate dynamically enabling and
    disabling the WebVR polyfill, and is not necessary for most WebVR apps.
    If you want to use the polyfill in your app, just include the js file and
    everything will work the way you want it to by default. -->
    <script>
      // Prevents the polyfill from initializing automatically.
      var WebVRConfig = { DEFER_INITIALIZATION: true }
    </script>
    <script src="js/third-party/webvr-polyfill.js"></script>
    <script src="js/third-party/wglu/wglu-url.js"></script>
    <script>
      // Dynamically turn the polyfill on if requested by the query args.
      if (WGLUUrl.getBool('polyfill', false)) { InitializeWebVRPolyfill(); }
    </script>
    <!-- End sample polyfill enabling logic -->

    <script src="js/third-party/gl-matrix-min.js"></script>

    <script src="js/third-party/wglu/wglu-program.js"></script>
    <script src="js/third-party/wglu/wglu-stats.js"></script>
    <script src="js/third-party/wglu/wglu-texture.js"></script>

    <script src="js/vr-cube-sea.js"></script>
    <script src="js/vr-samples-util.js"></script>
  </head>
  <body>
    <canvas id="webgl-canvas"></canvas>
    <script>
      /* global mat4, VRCubeSea, VRSamplesUtil, WGLUStats, WGLUTextureLoader */
      (function () {
      "use strict";

      var vrDisplay = null;
      var projectionMat = mat4.create();
      var viewMat = mat4.create();

      // ===================================================
      // WebGL scene setup. This code is not WebVR specific.
      // ===================================================

      // WebGL setup.
      var webglCanvas = document.getElementById("webgl-canvas");
      var glAttribs = {
        alpha: false,
        antialias: !VRSamplesUtil.isMobile()
      };
      var gl = webglCanvas.getContext("webgl", glAttribs);
      gl.clearColor(0.1, 0.2, 0.3, 1.0);
      gl.enable(gl.DEPTH_TEST);
      gl.enable(gl.CULL_FACE);

      var textureLoader = new WGLUTextureLoader(gl);
      var texture = textureLoader.loadTexture("media/textures/cube-sea.png");
      var cubeSea = new VRCubeSea(gl, texture);

      var stats = new WGLUStats(gl);

      function onResize () {
        webglCanvas.width = webglCanvas.offsetWidth * window.devicePixelRatio;
        webglCanvas.height = webglCanvas.offsetHeight * window.devicePixelRatio;
      }
      window.addEventListener("resize", onResize, false);
      onResize();

      // ================================
      // WebVR-specific code begins here.
      // ================================

      if (navigator.getVRDisplays) {
        navigator.getVRDisplays().then(function (displays) {
          if (displays.length > 0) {
            vrDisplay = displays[0];
            VRSamplesUtil.addButton("Reset Pose", "R", null, function () { vrDisplay.resetPose(); });
          } else {
            VRSamplesUtil.addInfo("WebVR supported, but no VRDisplays found.", 3000);
          }
        });
      } else if (navigator.getVRDevices) {
        VRSamplesUtil.addError("Your browser supports WebVR but not the latest version. See <a href='http://webvr.info'>webvr.info</a> for more info.");
      } else {
        VRSamplesUtil.addError("Your browser does not support WebVR. See <a href='http://webvr.info'>webvr.info</a> for assistance.");
      }

      // Renders the scene from the viewpoint of the given eye and pose.
      function renderEyeView (pose, eye) {
        var orientation = pose.orientation;
        var position = pose.position;
        if (!orientation) { orientation = [0, 0, 0, 1]; }
        if (!position) { position = [0, 0, 0]; }

        // Now that we're rendering for a specific eye, we need to use the FOV
        // for that eye to generate the projection matrix. glMatrix has a
        // function specifically for this, but if you're using a different
        // library the algorithm needed is defined in the WebVR spec.
        mat4.perspectiveFromFieldOfView(projectionMat, eye.fieldOfView, 0.1, 1024.0);

        // Same matrix creation as last time, but done in an intermediate matrix
        // so that it can be multiplied by the eye offset matrix.
        mat4.fromRotationTranslation(viewMat, orientation, position);

        // We need to translate the view matrix by the eye's offset in order to
        // get the desired stereo effect.
        mat4.translate(viewMat, viewMat, eye.offset);

        mat4.invert(viewMat, viewMat);

        // Render the scene for this eye.
        cubeSea.render(projectionMat, viewMat, stats);
      }

      function onAnimationFrame (t) {
        window.requestAnimationFrame(onAnimationFrame);

        stats.begin();

        gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);

        if (vrDisplay) {
          // When a VR display is available, render a stereo view of the scene
          // based on the display's pose.
          var pose = vrDisplay.getPose();

          // For each eye we'll adjust the viewport to only render to half the
          // canvas, which will give us the "split screen" output that we want.

          // VRDevice.getEyeParameters gets the current parameters each eye
          // should be rendered with. These values may change from frame to
          // frame, so the best practice is to query them each time instead of
          // caching them.

          // Left eye.
          gl.viewport(0, 0, webglCanvas.width * 0.5, webglCanvas.height);
          renderEyeView(pose, vrDisplay.getEyeParameters("left"));

          // Right eye.
          gl.viewport(webglCanvas.width * 0.5, 0, webglCanvas.width * 0.5, webglCanvas.height);
          renderEyeView(pose, vrDisplay.getEyeParameters("right"));

          gl.viewport(0, 0, webglCanvas.width, webglCanvas.height);
          stats.renderOrtho();
        } else {
          // No VRDisplay found. Render a normal mono view to the entire canvas.
          gl.viewport(0, 0, webglCanvas.width, webglCanvas.height);
          mat4.perspective(projectionMat, Math.PI*0.4, webglCanvas.width/webglCanvas.height, 0.1, 1024.0);
          mat4.identity(viewMat);
          cubeSea.render(projectionMat, viewMat, stats);
          stats.renderOrtho();
        }

        stats.end();
      }
      window.requestAnimationFrame(onAnimationFrame);
      })();
    </script>
  </body>
</html>
